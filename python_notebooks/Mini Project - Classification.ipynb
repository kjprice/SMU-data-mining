{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "We continue our work, with census data, from [Project 1](https://gist.github.com/kjprice/820c75bd8e5c3f2558f4576f38893dae), to take a deeper look into our data. We move beyond exploratory data analysis and will now look into classifying the data based on the given attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load in raw dataset\n",
    "person_raw = pd.read_csv('../data/person-subset-2.5percent.csv')\n",
    "\n",
    "# clean data (as performed in Project 1)\n",
    "# will provide us with a new dataset \"df\"\n",
    "# ...and a list of \"important_features\"\n",
    "execfile('../python/clean_data_person.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of the `important_features` discovered from the previous project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60357 entries, 0 to 78317\n",
      "Data columns (total 12 columns):\n",
      "PINCP     60357 non-null float64\n",
      "POVPIP    57892 non-null float64\n",
      "JWMNP     32486 non-null float64\n",
      "AGEP      60357 non-null int64\n",
      "PWGTP     60357 non-null int64\n",
      "PAP       60357 non-null float64\n",
      "CIT       60357 non-null object\n",
      "OC        60357 non-null bool\n",
      "ENG       60357 non-null object\n",
      "COW       60357 non-null object\n",
      "PUMA      60357 non-null category\n",
      "SEX       60357 non-null object\n",
      "dtypes: bool(1), category(1), float64(4), int64(2), object(4)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df[important_features].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Categorical Variable\n",
    "\n",
    "Along with these attributes above, as defined in our [previous project](https://gist.github.com/kjprice/820c75bd8e5c3f2558f4576f38893dae), we will want to add another variable which we will use to perform a classification analysis on. This variable should be categorical and would, ideally, continue on with our theme of \"predicting income\". Income (`PINCP`), as we have it currently, is a continuous variable. We will take income and will create a new categorical variable called `affluency`, which will take on the values \"general\" and \"rich\" based on whether the individual makes less (or more) than $100,000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['affluency'] = pd.cut(df.PINCP, [-1, 99999.99, 1e12], labels=('general', 'rich'))\n",
    "\n",
    "important_features = important_features + ['affluency']\n",
    "\n",
    "lr = df[important_features].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "Now that we have our new categorical variable, and a new dataset (`lr`) based on our `important_features`, let's try to clean up our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will remove unwanted fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del lr['POVPIP']\n",
    "del lr['PUMA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we group \"Travel Time\" (`JWMNP`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr.JWMNP = lr.JWMNP.fillna(-1)\n",
    "lr['travel_time'] = pd.cut(lr.JWMNP, (-2, 0, 15, 40, 60, lr.JWMNP.max()), labels=['na', 'short', 'half hour', 'hour', 'long'])\n",
    "del lr['JWMNP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, from our variables `affluency` and `SEX`, we will create the boolean variables `wealthy` and `is_male` respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr['wealthy'] = lr.affluency == 'rich'\n",
    "del lr['affluency']\n",
    "lr['is_male'] = lr.SEX == 'Male'\n",
    "lr.is_male = lr.is_male.astype(np.int)\n",
    "del lr['SEX']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can perform one-hot-encoding on our other categorical variables `travel_time`, `CIT`, `ENG`, `COW`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_travel_time = pd.get_dummies(lr.travel_time, prefix='Travel_Time_')\n",
    "del lr['travel_time']\n",
    "one_hot_citizenship = pd.get_dummies(lr.CIT, prefix='Citizen_')\n",
    "lr = pd.concat((lr, one_hot_citizenship), axis=1)\n",
    "del lr['CIT']\n",
    "one_hot_english = pd.get_dummies(lr.ENG, prefix='English_')\n",
    "lr = pd.concat((lr, one_hot_english), axis=1)\n",
    "del lr['ENG']\n",
    "one_hot_worker_class = pd.get_dummies(lr.COW, prefix='Worker_Class_')\n",
    "del lr['COW']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our dataset looks now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60357 entries, 0 to 78317\n",
      "Data columns (total 17 columns):\n",
      "PINCP                           60357 non-null float64\n",
      "AGEP                            60357 non-null int64\n",
      "PWGTP                           60357 non-null int64\n",
      "PAP                             60357 non-null float64\n",
      "OC                              60357 non-null bool\n",
      "wealthy                         60357 non-null bool\n",
      "is_male                         60357 non-null int64\n",
      "Citizen__Born Abroad)           60357 non-null uint8\n",
      "Citizen__Naturalized            60357 non-null uint8\n",
      "Citizen__Non-Citizen            60357 non-null uint8\n",
      "Citizen__US Born                60357 non-null uint8\n",
      "Citizen__US Territory Born      60357 non-null uint8\n",
      "English__Not at all             60357 non-null uint8\n",
      "English__Not well               60357 non-null uint8\n",
      "English__Speaks only English    60357 non-null uint8\n",
      "English__Very well              60357 non-null uint8\n",
      "English__Well                   60357 non-null uint8\n",
      "dtypes: bool(2), float64(2), int64(3), uint8(10)\n",
      "memory usage: 3.5 MB\n"
     ]
    }
   ],
   "source": [
    "lr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so we now we have numeric fields to work with. now we can begin our analysis..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can create our response `y` and explanatory `X` variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Create reponse and explanatory variables\n",
    "lr2 = lr.copy(deep=True)\n",
    "y = lr2.wealthy.values\n",
    "del lr2['wealthy']\n",
    "X = lr2.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we prepare 3 iterations that will be made to test our model using 80% of the dataset for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cv_iterations = 3\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create reusable logistic regression object, which we will fit our model upon later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over our testing/training sets while recording the accuracy of our model from each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. accuracy: 0.9687\n",
      "1. accuracy: 0.9718\n",
      "2. accuracy: 0.9689\n"
     ]
    }
   ],
   "source": [
    "iter_num = 0\n",
    "for train_indices, test_indices in cv_object.split(X,y):\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train, y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    \n",
    "    acc = mt.accuracy_score(y_test, y_hat)\n",
    "\n",
    "    print('%d. accuracy: %s' % (iter_num, round(acc, 4)))\n",
    "    iter_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 97% accuracy. Not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kjprice/anaconda/envs/python2/lib/python2.7/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedShuffleSplit( n_splits=1,test_size=0.5)\n",
    "regularize_const = 0.1\n",
    "iterations = 5\n",
    "svm_sgd = SGDClassifier(alpha=regularize_const,\n",
    "        fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
    "        loss='hinge', n_iter=iterations, n_jobs=-1, penalty='l2')\n",
    "\n",
    "scl = StandardScaler()\n",
    "for train_idx, test_idx in cv.split(X,y):\n",
    "    svm_sgd.fit(scl.fit_transform(X[train_idx]),y[train_idx])\n",
    "    yhat = svm_sgd.predict(scl.transform(X[test_idx]))\n",
    "    \n",
    "    conf = mt.confusion_matrix(y[test_idx],yhat)\n",
    "    acc = mt.accuracy_score(y[test_idx],yhat)\n",
    "\n",
    "print('Accuracy: %s' % round(acc, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
