{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "We continue our work, with census data, from [Project 1](https://gist.github.com/kjprice/820c75bd8e5c3f2558f4576f38893dae) and the [Mini Project](https://gist.github.com/kjprice/bb3ecd63e7a2e5050c018d63c875a79b), to take a deeper look into our data. We move beyond exploratory data analysis and will now look into classifying the data based on the given attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# load in raw dataset\n",
    "person_raw = pd.read_csv('../data/person-subset-2.5percent.csv')\n",
    "\n",
    "# clean data (as performed in Project 1)\n",
    "# will provide us with a new dataset \"df\"\n",
    "# ...and a list of \"important_features\"\n",
    "execfile('../python/clean_data_person.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of the `important_features` discovered from the first project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60357 entries, 0 to 60356\n",
      "Data columns (total 15 columns):\n",
      "PINCP        60357 non-null float64\n",
      "POVPIP       57892 non-null float64\n",
      "JWMNP        32486 non-null float64\n",
      "AGEP         60357 non-null int64\n",
      "PWGTP        60357 non-null int64\n",
      "PAP          60357 non-null float64\n",
      "CIT          60357 non-null object\n",
      "ENG          60357 non-null object\n",
      "COW          60357 non-null object\n",
      "PUMA         60357 non-null category\n",
      "SEX          60357 non-null object\n",
      "MIL          60357 non-null object\n",
      "SCHL         60357 non-null float64\n",
      "MAR          60357 non-null object\n",
      "affluency    60312 non-null category\n",
      "dtypes: category(2), float64(5), int64(2), object(6)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df[important_features].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Descriptions\n",
    "\n",
    "Attributes used with their descriptions:\n",
    "  * AGEP:  Age of person (continuous 0-95)\n",
    "  * CIT:  Citizenship status (categorical - numerical key)\n",
    "  * CIT_CAT:  Citizenship status (categorical - string)\n",
    "  * COW:  Class of worker (categorical - string)\n",
    "  * ENG:  Ability to speak English (categorical scale of 1-4 and native speakers)\n",
    "  * JWMNP:  Travel time to work (continuous - minutes of commute to work)\n",
    "  * JWTR:  Means of transportation to work (categorical - 12 modes of transportation)\n",
    "  * MAR:  Marital status (categorical - 5 categories: married, divorced, separated, single, widow)\n",
    "  * PAP:  Public assistance income past 12 months (continuous variable of dollars of assistance received)\n",
    "  * PINCP:  Total person's income (continuous of total income)\n",
    "  * POVPIP:  Income-to-poverty ratio recode (continuous with a cap at 501)\n",
    "  * SCHL:  Educational attainment (continuous - years of completed education)\n",
    "  * SEX:  Sex (gender of female or male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification variable\n",
    "\n",
    "As performed in the previous assignment, we have created a new variable called `affluency` which can be one of two levels \"general\" or \"rich\" (greater than $100,000 income):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_affluency():\n",
    "    global lr\n",
    "    global important_features\n",
    "\n",
    "    lr = df[important_features].copy(deep=True)\n",
    "    lr['affluency'] = pd.cut(df.PINCP, [-1, 99999.99, 1e12], labels=('general', 'rich'))\n",
    "create_affluency()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "As performed in the previous project, we cleanup our dataset further. We delete variables which we do not need: \n",
    " - `POVPIP`\n",
    " - `PINCP`\n",
    " - `PUMA`\n",
    " - `MIL`\n",
    " - `MAR`\n",
    " - `SCHL`\n",
    "\n",
    "We group \"Travel Time\" (`JWMNP`) into appropriate intervals (previously a continuous variable):\n",
    " - `na`\n",
    " - `short`\n",
    " - `half hour`\n",
    " - `hour`\n",
    " - `long`\n",
    " \n",
    "Then, from our variables `affluency` and `SEX`, we will create the boolean variables `wealthy` and `is_male` respectively.\n",
    "\n",
    "Finally, we can perform one-hot-encoding on our other categorical variables `travel_time`, `CIT`, `ENG`, `COW`.\n",
    "\n",
    "All of this gives us the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60357 entries, 0 to 60356\n",
      "Data columns (total 48 columns):\n",
      "AGEP                                               60357 non-null int64\n",
      "PWGTP                                              60357 non-null int64\n",
      "PAP                                                60357 non-null float64\n",
      "wealthy                                            60357 non-null bool\n",
      "is_male                                            60357 non-null int64\n",
      "Travel_Time__half hour                             60357 non-null uint8\n",
      "Travel_Time__hour                                  60357 non-null uint8\n",
      "Travel_Time__long                                  60357 non-null uint8\n",
      "Travel_Time__na                                    60357 non-null uint8\n",
      "Travel_Time__short                                 60357 non-null uint8\n",
      "Citizen__Born Abroad)                              60357 non-null uint8\n",
      "Citizen__Naturalized                               60357 non-null uint8\n",
      "Citizen__Non-Citizen                               60357 non-null uint8\n",
      "Citizen__US Born                                   60357 non-null uint8\n",
      "Citizen__US Territory Born                         60357 non-null uint8\n",
      "English__Not at all                                60357 non-null uint8\n",
      "English__Not well                                  60357 non-null uint8\n",
      "English__Speaks only English                       60357 non-null uint8\n",
      "English__Very well                                 60357 non-null uint8\n",
      "English__Well                                      60357 non-null uint8\n",
      "Worker_Class__Family Business - no pay             60357 non-null uint8\n",
      "Worker_Class__Federal Government                   60357 non-null uint8\n",
      "Worker_Class__Local Government                     60357 non-null uint8\n",
      "Worker_Class__Private Non-Profit                   60357 non-null uint8\n",
      "Worker_Class__Private for Profit                   60357 non-null uint8\n",
      "Worker_Class__Self Employed (incorporated)         60357 non-null uint8\n",
      "Worker_Class__Self Employed (not incorportated)    60357 non-null uint8\n",
      "Worker_Class__State Government                     60357 non-null uint8\n",
      "Worker_Class__Unemployeed                          60357 non-null uint8\n",
      "Worker_Class__nan                                  60357 non-null uint8\n",
      "Miliary_Service__Never Served                      60357 non-null uint8\n",
      "Miliary_Service__Reserves                          60357 non-null uint8\n",
      "Miliary_Service__Served Not Active                 60357 non-null uint8\n",
      "Miliary_Service__Serving Active Duty               60357 non-null uint8\n",
      "Education_Attained__HS_diploma                     60357 non-null uint8\n",
      "Education_Attained__bacholors_degree               60357 non-null uint8\n",
      "Education_Attained__doctorate_degree               60357 non-null uint8\n",
      "Education_Attained__masters_degree                 60357 non-null uint8\n",
      "Education_Attained__na                             60357 non-null uint8\n",
      "Education_Attained__no_high_school                 60357 non-null uint8\n",
      "Education_Attained__professional_degree            60357 non-null uint8\n",
      "Education_Attained__some_college                   60357 non-null uint8\n",
      "Education_Attained__some_high_school               60357 non-null uint8\n",
      "Marital_status__Divorced                           60357 non-null uint8\n",
      "Marital_status__Married                            60357 non-null uint8\n",
      "Marital_status__Never Married                      60357 non-null uint8\n",
      "Marital_status__Separated                          60357 non-null uint8\n",
      "Marital_status__Widowed                            60357 non-null uint8\n",
      "dtypes: bool(1), float64(1), int64(3), uint8(43)\n",
      "memory usage: 4.8 MB\n"
     ]
    }
   ],
   "source": [
    "execfile('../python/clean_data_classification.py')\n",
    "lr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A principal components analysis is also performed with five components on a scaled-version of our dataset. We may decide to use this later on in our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA_0</th>\n",
       "      <th>PCA_1</th>\n",
       "      <th>PCA_2</th>\n",
       "      <th>PCA_3</th>\n",
       "      <th>PCA_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.884722</td>\n",
       "      <td>1.800257</td>\n",
       "      <td>0.924182</td>\n",
       "      <td>-0.699644</td>\n",
       "      <td>-0.178205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.337951</td>\n",
       "      <td>-1.349852</td>\n",
       "      <td>0.459928</td>\n",
       "      <td>-0.865059</td>\n",
       "      <td>0.822025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.203093</td>\n",
       "      <td>-0.315044</td>\n",
       "      <td>-0.527054</td>\n",
       "      <td>-0.989047</td>\n",
       "      <td>1.147465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.173147</td>\n",
       "      <td>-1.279213</td>\n",
       "      <td>-0.209784</td>\n",
       "      <td>-0.614140</td>\n",
       "      <td>-0.449465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.361579</td>\n",
       "      <td>1.421788</td>\n",
       "      <td>-0.016835</td>\n",
       "      <td>-1.109769</td>\n",
       "      <td>0.966567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PCA_0     PCA_1     PCA_2     PCA_3     PCA_4\n",
       "0  1.884722  1.800257  0.924182 -0.699644 -0.178205\n",
       "1  0.337951 -1.349852  0.459928 -0.865059  0.822025\n",
       "2 -1.203093 -0.315044 -0.527054 -0.989047  1.147465\n",
       "3 -0.173147 -1.279213 -0.209784 -0.614140 -0.449465\n",
       "4  1.361579  1.421788 -0.016835 -1.109769  0.966567"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[pca_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, we are hoping to classify individuals as either _wealthy_ (income > \\$100,000) or _general_ (income < \\$100,000). Being so, we want our model to be as accurate as possible and will consider accuracy to be the most important metric.\n",
    "\n",
    "Our dataset is highly unbalanced with only 7% of the population being classified as \"wealthy\". Because of this unbalance, we want to keep an eye on the F-measure. A model may choose to take the easy way out, obtaining nearly 92% accuracy by simply classifying all individuals as \"general\". The F-measure will be a secondary metric to accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help ensure that overfitting is mitigated, we will use a 10-fold cross validation technique to split our dataset. Because our dataset is so unbalanced, we will use a stratified k-fold cross validator.\n",
    "\n",
    "Additionally, we will scale our dataset so that various classification techniques can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_stratified_transformed_dataset():\n",
    "   global lr2\n",
    "   ### Create reponse and explanatory variables\n",
    "   lr2 = lr.copy(deep=True)\n",
    "   y = lr2.wealthy.values\n",
    "   del lr2['wealthy']\n",
    "   X = lr2.values\n",
    "   \n",
    "   ### Standardize X values\n",
    "   scl_obj = MinMaxScaler()\n",
    "   scl_obj.fit(X)\n",
    "   X = scl_obj.transform(X)\n",
    "   \n",
    "   skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "   skf.get_n_splits(X, y)\n",
    "   \n",
    "   _data = []\n",
    "   for train_index, test_index in skf.split(X, y):\n",
    "      X_train, X_test = X[train_index], X[test_index]\n",
    "      y_train, y_test = y[train_index], y[test_index]\n",
    "      _data.append([X_train, X_test, y_train, y_test])\n",
    "      \n",
    "   return _data\n",
    "\n",
    "\n",
    "test_train_data = create_stratified_transformed_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to classify the individuals of our dataset as being wealthy (or not) using several techniques including Naive Bayes, Decision Trees, and KNN. Then we will try to regress our dataset to predict the actual income of the individual using linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create two functions to help us with cognitive overload by cleaning our code down to the essential pieces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_accuracy(title, accuracy, avg=False):\n",
    "    accuracy = round(accuracy*100, 2)\n",
    "    avg_text = 'avg' if avg else ''\n",
    "    bullet = ''\n",
    "    if not avg:\n",
    "       bullet = '**'\n",
    "    print('%s%s%% %s accuracy - %s' % (bullet, accuracy, avg_text, title))\n",
    "\n",
    "def fit_and_test(title, test_train, show_individual_accuracies=False, print_confusion=False):\n",
    "   accuracies = pd.Series()\n",
    "   for X_train, X_test, y_train, y_test in test_train_data:\n",
    "      test_train.fit(X_train, y_train)\n",
    "      y_hat = test_train.predict(X_test)\n",
    "      \n",
    "      acc = mt.accuracy_score(y_test, y_hat)\n",
    "      accuracies = accuracies.append(pd.Series(acc))\n",
    "      \n",
    "      if print_confusion:\n",
    "         print(mt.confusion_matrix(y_test, y_hat))\n",
    "      \n",
    "      if show_individual_accuracies:\n",
    "         print_accuracy(title, acc)\n",
    "   print_accuracy(title, accuracies.mean(), avg=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.7% avg accuracy - decision tree (no max feature)\n",
      "89.73% avg accuracy - decision tree (max_features=4)\n",
      "92.28% avg accuracy - Random Forest\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(max_features=None, class_weight='balanced')\n",
    "fit_and_test('decision tree (no max feature)', dt_clf)\n",
    "dt_clf = DecisionTreeClassifier(max_features=4, class_weight='balanced')\n",
    "fit_and_test('decision tree (max_features=4)', dt_clf)\n",
    "dt_clf = RandomForestClassifier(class_weight='balanced')\n",
    "fit_and_test('Random Forest', dt_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get nearly **90%** accuracy using a decision tree. We are not seeing much difference when changing the `max_features` parameter except a slight speed boost when limiting the featuers. Using a random forest, however, seems to give us a bit of a boost in accuracy of about **92%** total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.74% avg accuracy - bayes multinomial (alpha=100)\n",
      "92.82% avg accuracy - bayes multinomial (alpha=1)\n",
      "92.82% avg accuracy - bayes multinomial (alpha=.001)\n"
     ]
    }
   ],
   "source": [
    "mb_clf = MultinomialNB(alpha=100)\n",
    "fit_and_test('bayes multinomial (alpha=100)', mb_clf, show_individual_accuracies=False)\n",
    "mb_clf = MultinomialNB(alpha=1)\n",
    "fit_and_test('bayes multinomial (alpha=1)', mb_clf, show_individual_accuracies=False)\n",
    "mb_clf = MultinomialNB(alpha=.001)\n",
    "fit_and_test('bayes multinomial (alpha=.001)', mb_clf, show_individual_accuracies=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With multinomial Bayes, we are getting an accuracy around **93%** consistently. A chance in the `alpha` parameter does not seem to produce a significant change in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
