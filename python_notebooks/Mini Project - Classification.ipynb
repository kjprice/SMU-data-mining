{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "We continue our work, with census data, from [Project 1](https://gist.github.com/kjprice/820c75bd8e5c3f2558f4576f38893dae), to take a deeper look into our data. We move beyond exploratory data analysis and will now look into classifying the data based on the given attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# load in raw dataset\n",
    "person_raw = pd.read_csv('../data/person-subset-2.5percent.csv')\n",
    "\n",
    "# clean data (as performed in Project 1)\n",
    "# will provide us with a new dataset \"df\"\n",
    "# ...and a list of \"important_features\"\n",
    "execfile('../python/clean_data_person.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of the `important_features` discovered from the previous project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60357 entries, 0 to 78317\n",
      "Data columns (total 12 columns):\n",
      "PINCP     60357 non-null float64\n",
      "POVPIP    57892 non-null float64\n",
      "JWMNP     32486 non-null float64\n",
      "AGEP      60357 non-null int64\n",
      "PWGTP     60357 non-null int64\n",
      "PAP       60357 non-null float64\n",
      "CIT       60357 non-null object\n",
      "OC        60357 non-null bool\n",
      "ENG       60357 non-null object\n",
      "COW       60357 non-null object\n",
      "PUMA      60357 non-null category\n",
      "SEX       60357 non-null object\n",
      "dtypes: bool(1), category(1), float64(4), int64(2), object(4)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df[important_features].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Categorical Variable\n",
    "\n",
    "Along with these attributes above, as defined in our [previous project](https://gist.github.com/kjprice/820c75bd8e5c3f2558f4576f38893dae), we will want to add another variable which we will use to perform a classification analysis on. This variable should be categorical and would, ideally, continue on with our theme of \"predicting income\". Income (`PINCP`), as we have it currently, is a continuous variable. We will take income and will create a new categorical variable called `affluency`, which will take on the values \"general\" and \"rich\" based on whether the individual makes less (or more) than $100,000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['affluency'] = pd.cut(df.PINCP, [-1, 99999.99, 1e12], labels=('general', 'rich'))\n",
    "\n",
    "important_features = important_features + ['affluency']\n",
    "\n",
    "lr = df[important_features].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "Now that we have our new categorical variable, and a new dataset (`lr`) based on our `important_features`, let's try to clean up our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will remove unwanted fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del lr['POVPIP']\n",
    "del lr['PUMA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we group \"Travel Time\" (`JWMNP`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr.JWMNP = lr.JWMNP.fillna(-1)\n",
    "lr['travel_time'] = pd.cut(lr.JWMNP, (-2, 0, 15, 40, 60, lr.JWMNP.max()), labels=['na', 'short', 'half hour', 'hour', 'long'])\n",
    "del lr['JWMNP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, from our variables `affluency` and `SEX`, we will create the boolean variables `wealthy` and `is_male` respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr['wealthy'] = lr.affluency == 'rich'\n",
    "del lr['affluency']\n",
    "lr['is_male'] = lr.SEX == 'Male'\n",
    "lr.is_male = lr.is_male.astype(np.int)\n",
    "del lr['SEX']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can perform one-hot-encoding on our other categorical variables `travel_time`, `CIT`, `ENG`, `COW`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_travel_time = pd.get_dummies(lr.travel_time, prefix='Travel_Time_')\n",
    "del lr['travel_time']\n",
    "one_hot_citizenship = pd.get_dummies(lr.CIT, prefix='Citizen_')\n",
    "lr = pd.concat((lr, one_hot_citizenship), axis=1)\n",
    "del lr['CIT']\n",
    "one_hot_english = pd.get_dummies(lr.ENG, prefix='English_')\n",
    "lr = pd.concat((lr, one_hot_english), axis=1)\n",
    "del lr['ENG']\n",
    "one_hot_worker_class = pd.get_dummies(lr.COW, prefix='Worker_Class_')\n",
    "del lr['COW']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our dataset looks now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60357 entries, 0 to 78317\n",
      "Data columns (total 17 columns):\n",
      "PINCP                           60357 non-null float64\n",
      "AGEP                            60357 non-null int64\n",
      "PWGTP                           60357 non-null int64\n",
      "PAP                             60357 non-null float64\n",
      "OC                              60357 non-null bool\n",
      "wealthy                         60357 non-null bool\n",
      "is_male                         60357 non-null int64\n",
      "Citizen__Born Abroad)           60357 non-null uint8\n",
      "Citizen__Naturalized            60357 non-null uint8\n",
      "Citizen__Non-Citizen            60357 non-null uint8\n",
      "Citizen__US Born                60357 non-null uint8\n",
      "Citizen__US Territory Born      60357 non-null uint8\n",
      "English__Not at all             60357 non-null uint8\n",
      "English__Not well               60357 non-null uint8\n",
      "English__Speaks only English    60357 non-null uint8\n",
      "English__Very well              60357 non-null uint8\n",
      "English__Well                   60357 non-null uint8\n",
      "dtypes: bool(2), float64(2), int64(3), uint8(10)\n",
      "memory usage: 3.5 MB\n"
     ]
    }
   ],
   "source": [
    "lr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so we now we have numeric fields to work with. now we can begin our analysis..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
